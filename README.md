# Attention-Guided Response Verification Tool

This project aims to verify answers generated by a Large Language Model (LLM) for questions about a long document by analyzing the model's attention patterns.

## Setup

1.  **Clone the repository (or set up locally):**
    ```bash
    # cd into your project directory
    ```
2.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Configure:** Review and potentially modify settings in `config.py` (e.g., model paths if not using default cache).
4.  **Download Model:** Ensure the model specified in `config.py` (`meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8`) is downloaded and accessible by your environment (this might happen automatically on first run depending on the loading library).

## Usage

Run the main script from the project root directory:

```bash
python main.py <path_to_document> "<your_question>"